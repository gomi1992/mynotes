# 文件同步算法
tags = #算法 #同步 #rsync

[rsync算法](https://rsync.samba.org/tech_report/tech_report.html)

# 分块checksum
两种checksum算法：弱checksum算法-
[adler-32](https://en.wikipedia.org/wiki/Adler-32)
，强checksum算法-MD5 hash。

弱checksum，32位，效率高，但容易碰撞，也就说不同两个块的checksum可能一样的概率相对较高。

强checksum，128位，速度慢，不容易碰撞。

弱强结合，先使用弱checksum计算，若不一样则肯定不一样，若一样再用强算法计算。

也就是说，弱的checksum是用来区别不同，而强的是用来确认相同。

# 文件比较
比较两个文件不同相对来说比较简单。

而比较两个文件具体哪里不同比较复杂。

## checksum存放
在服务端，checksum一般存放在一个hash表中，查找效率O(1)，这样接收到客户端发来的checksum就不需要线性的搜索。

## rolling-checksum
例如以512字节为一块。

我现在计算了[0,512)的checksum，那如果我想计算[1,513)的checksum，我是不是一定要重新计算，能够使用[0,512)的checksum么？

[Rabin-Karp 算法](https://en.wikipedia.org/wiki/Rabin%E2%80%93Karp_algorithm)

这个算法比较简单，我举个例子，我们有一个数字：12345678，假设我们以5个长度作为一个块，那么，第一个块就是 12345 ，12345可以表示为：

$$ 1 * 10^4 + 2 * 10^3 + 3 * 10^2 + 4 * 10^1 + 5 * 10^0 = 12345 $$

如果我们要step 1步，也就是要得到 23456， 我们不必计算：

$$ 2 * 10^4 + 3 * 10^3 + 4 * 10^2 + 5 * 10^1 + 6 * 10^0 $$

而是直接计算：

$$ (12345 - 1 * 10^4) * 10 + 6 * 10 ^0 $$

我们可以看到，其中，我们把12345最左边第一位去掉，然后，再加上最右边的一位。这就是Rolling checksum的算法。

实际的公式是：

$$ hash ( t[0, m-1] ) = t[0] * b^(m-1) + t[1] * b^[m-2] ..... t[m-1] * b^0 $$

其中的 b是一个常数基数，在 Rabin-Karp 算法中，我们一般取值为  256。

于是，在计算 hash ( t[1, m] ) 时，只需要下面这样就可以了：

$$ hash( t[1, m] ) = hash ( t[0, m-1] ) - t[0] * b^(m-1)  + t[m] * b ^0 $$

[参考文献1](https://coolshell.cn/articles/7425.html)

# 总结
近来被浏览器书签同步所困扰，想自己实现一个书签同步插件和服务端，于是研究了下文件同步算法，深受启发。

如果我对某一块中某一字节修改了，那是不是那一块数据我都需要重传？